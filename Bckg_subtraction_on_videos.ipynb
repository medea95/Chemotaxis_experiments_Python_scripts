{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background substraction and pipette properties detection\n",
    "\n",
    "This script takes as input: \n",
    "* a video of the chemotaxis experiment \n",
    "\n",
    "and returns as output:\n",
    "\n",
    " * the bckg substracted black and white video \n",
    " * a dictionary with the pipette properties: countour lines, xy coordinates of the pipette entrance centers and inclination angle with respect to the horizontal    \n",
    " * a control image to check if the contour of the pipette is well detected\n",
    " \n",
    " \n",
    "what if the pipette detection is wrong?\n",
    "\n",
    "Check on the control image that the pipette detection is good: countour, entrance center position and angle (to check if the angle is right, check if the line traced in the center of the pipette passes from the entrance center). \n",
    "The detection can be bad for various reasons: \n",
    "\n",
    "* **check the binary image**: is the white profile of the pipette smooth? The pipette shape should be white and the background homogenously black. If there are white or black spots where there shouldn't, **try to change the threshold** in the conversion from greyscale to binary:  the parameter \"threshold\" is the number in the grey scale above which the color will be turned to white in the binary image. If there are white spots, increase the threshold, if there are black spots, decrease the threshold \n",
    "\n",
    "* **check the plateau size**: the pipette external thick border is detected as a wide white plateau in the binary image. **Increasing or reducing the plateau size** can be improve the detection of the contour \n",
    "\n",
    "* **Is the video short?** the fewer the frames, the worst are the outputs!\n",
    "\n",
    "\n",
    "*Written by Medea Zanoli on 02/01/2021*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance, ImageSequence, ImageOps,  ImageChops, ImageFilter,  ImageDraw\n",
    "\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askdirectory, askopenfilename\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from progressbar import ProgressBar\n",
    "import progressbar\n",
    "\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from matplotlib import path\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the video to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imput_video = askopenfilename() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually select the folder where to save the outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path =  askdirectory() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chose the name under which the outouts will be saved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video name \n",
    "video_name = 'prova'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate background and pipette properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting images and computing background...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bckg computation is done\n",
      "saving bckg subtracted images in a video...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video post-processing is done\n",
      "calculation of pipette properties...\n",
      "Using matplotlib backend: <object object at 0x000001A930C7BC90>\n",
      "Using matplotlib backend: QtAgg\n"
     ]
    }
   ],
   "source": [
    "# IF THE PIPETTE DETECTION IS BAD...\n",
    "# ...TRY TO CHANGE THE THRESHOLD!: thresh is the number in the grey scale above which there will be white in \n",
    "# the binary image. \n",
    "# If thresh is too low, blurry areas around the pipette can become parts of the pipette in the conversion to a binary image\n",
    "threshold = 240\n",
    "# IF THE PIPETTE DETECTION IS BAD...\n",
    "# try change the plateau size \n",
    "plateau_size = [2, 7]# max and min number of pixels of the pipette internal contour   \n",
    "\n",
    "# import video to process\n",
    "cap= cv2.VideoCapture(imput_video)\n",
    "\n",
    "# define a progress bar object\n",
    "bar = ProgressBar(maxval=int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "bar.start()\n",
    "\n",
    "# background computation\n",
    "print('Extracting images and computing background...')\n",
    "\n",
    "i=0\n",
    "images_array = [] # here we save the video frames while computing brackground \n",
    "bckg_arr = np.zeros(np.shape(cap.read()[1])[0:2]) # initialize background matrix to zero, get the shape from the first file\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    \n",
    "    ret, frame = cap.read() \n",
    "    if ret == False:\n",
    "        break\n",
    "        \n",
    "    # image processing\n",
    "    im = Image.fromarray(frame, mode=\"RGB\")\n",
    "    im = im.convert(\"L\") # convert to greyscale\n",
    "    im = ImageOps.invert(im) # invert colors \n",
    "    im = ImageEnhance.Contrast(im).enhance(1.9) # increment contrast by .x % \n",
    "    \n",
    "    # save the processed image\n",
    "    im_arr = np.array(im, dtype=np.uint8)  # vectorize frame image in uint8 format and save it for later use\n",
    "    images_array.append(im_arr) #save image in an array \n",
    "    \n",
    "    # calculate background\n",
    "    bckg_arr = im_arr.astype(float) + bckg_arr.astype(float) # sum as float <-- important not to screw up evrything\n",
    "    i+=1 # frames counter to normalize the bckg \n",
    "    \n",
    "    bar.update(i) # updat progressbar\n",
    "    \n",
    "    \n",
    "bckg_arr = (bckg_arr/i).astype(np.uint8) # convert bckg to uint8\n",
    "bckg_im = Image.fromarray(bckg_arr,mode=\"L\")\n",
    "\n",
    "bckg_im.save(output_path + \"/\" + video_name + \"_bckg.pdf\")\n",
    "\n",
    "cap.release() # close imput video\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('bckg computation is done')\n",
    "\n",
    "# prepare video to save processed and bckg subtracted images \n",
    "print('saving bckg subtracted images in a video...')\n",
    "\n",
    "# prepare dimension for video file\n",
    "height, width = np.shape(bckg_arr)\n",
    "size = (width, height)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # format: great mistery\n",
    "\n",
    "# open an empty video file with the right dimensions\n",
    "out = cv2.VideoWriter(output_path +'/'+ video_name + '.avi', # directory and name of the video  \n",
    "                      fourcc,  \n",
    "                      30,  # frame per second in output video\n",
    "                      size, # framesize must match the image size \n",
    "                      0) # for grayscale \n",
    "\n",
    "bar = ProgressBar(maxval=progressbar.UnknownLength)\n",
    "\n",
    "for i in bar(range(len(images_array))):\n",
    "    # bckg substraction\n",
    "    im = Image.fromarray(images_array[i])\n",
    "    no_bckg = ImageChops.difference(im, bckg_im)\n",
    "    out.write(np.array(no_bckg, dtype=np.uint8))\n",
    "    \n",
    "#out.release()\n",
    "print('video post-processing is done')\n",
    "\n",
    "print('calculation of pipette properties...')\n",
    "\n",
    "# convert image to black and white for better pipette contour detection \n",
    "\n",
    "_, bckg_arr_binary=cv2.threshold(src=bckg_arr, thresh=threshold, maxval=255, type=cv2.THRESH_BINARY)\n",
    "Image.fromarray(bckg_arr_binary).save(output_path + \"/\" + video_name + \"binary_control_pipette_detection.pdf\")\n",
    "%matplotlib\n",
    "Image.fromarray(bckg_arr_binary).show()\n",
    "\n",
    "# extract pipette contours \n",
    "upper_contour_pipette = []\n",
    "lower_contour_pipette = []\n",
    "\n",
    "for column_index in np.arange(0,np.shape(bckg_arr)[1]): #np.shape(bckg_arr)[1]\n",
    "    \n",
    "    signal = bckg_arr_binary[:,column_index] # take all rows for each column \n",
    "    \n",
    "    # peaks index parameters: - distance : Required minimal horizontal distance (>= 1) in samples between neighbouring peaks. \n",
    "    #              - plateau_size: Required size of the flat top of peaks in samples\n",
    "    peaks_index, peaks_dict = find_peaks(signal, height = 250, distance= 30, plateau_size = plateau_size) # detect pipette internal peaks \n",
    "    \n",
    "    if(len(peaks_index) == 0): \n",
    "        break\n",
    "        \n",
    "    # MIGHT SUBSITUTE WITH SOME CLUSTERING? (divide in two groups based on distance)\n",
    "    upper_indexes = peaks_index[peaks_index < np.shape(bckg_im)[0]/2]  # assuming that the upper pipette is in the upper half of the image...  \n",
    "    lower_indexes = peaks_index[peaks_index >= np.shape(bckg_im)[0]/2]  #\n",
    "    \n",
    "    # upper pipette\n",
    "    if(len(upper_indexes) ==2 ): # if there are two peaks no problem: take internal part of pipette (the right edge of first peak abd left edge of second peak)\n",
    "        upper_contour_pipette.append( (column_index, peaks_dict['right_edges'][np.where(peaks_index == upper_indexes[0])][0]) ) \n",
    "        upper_contour_pipette.append( (column_index, peaks_dict['left_edges'][np.where(peaks_index == upper_indexes[1])][0]) ) \n",
    " \n",
    "      \n",
    "    # lower pipette \n",
    "    if(len(lower_indexes) ==2 ): # if there are two peaks no problem: take internal part of pipette\n",
    "        lower_contour_pipette.append( (column_index, peaks_dict['right_edges'][np.where(peaks_index == lower_indexes[0])][0]) ) \n",
    "        lower_contour_pipette.append( (column_index, peaks_dict['left_edges'][np.where(peaks_index == lower_indexes[1])][0]) ) \n",
    "\n",
    "# do a liner fit on pipette contours \n",
    "\n",
    "def func(x, a, b): # linear fit function \n",
    "    return a*x+b\n",
    "\n",
    "# defne arrays to fit \n",
    "x_up = np.array([i[0] for i in upper_contour_pipette[::2]]) # x-coordinate of the upper pipette\n",
    "x_low = np.array([i[0] for i in lower_contour_pipette[::2]]) \n",
    "\n",
    "y1 = np.array([i[1] for i in upper_contour_pipette[::2]]) # upper contour of the upper pipette\n",
    "y2 = np.array([i[1] for i in upper_contour_pipette[1::2]]) # lower contour of the upper pipette \n",
    "\n",
    "y3 = np.array([i[1] for i in lower_contour_pipette[::2]]) # upper contour of the lower pipette\n",
    "y4 = np.array([i[1] for i in lower_contour_pipette[1::2]]) # lower contour of the lower pipette \n",
    "\n",
    "# do the fit \n",
    "fit_param_y1,_ =  curve_fit(func, x_up, y1)\n",
    "fit_param_y2,_ =  curve_fit(func, x_up, y2)\n",
    "fit_param_y3,_ =  curve_fit(func, x_low, y3)\n",
    "fit_param_y4,_ =  curve_fit(func, x_low, y4)\n",
    "\n",
    "# complete possible gaps in the x\n",
    "x_up = np.arange(x_up[0], x_up[-1], 1 )\n",
    "x_low = np.arange(x_low[0], x_low[-1], 1 )\n",
    "\n",
    "# fit the pipette profile\n",
    "y1_fit = fit_param_y1[0]*x_up + fit_param_y1[1] # upper contour of the upper pipette fitted\n",
    "y2_fit = fit_param_y2[0]*x_up + fit_param_y2[1] # lower contour of the upper pipette fitted\n",
    "y3_fit = fit_param_y3[0]*x_low + fit_param_y3[1] # upper contour of the lower pipette fitted\n",
    "y4_fit = fit_param_y4[0]*x_low + fit_param_y4[1] # lower contour of the lower pipette fitted \n",
    "\n",
    "# save the contour line in the correct order for the pipette area to be closed :\n",
    "# upper left corner --> upper right corner --> lower right corner --> lower left corner\n",
    "\n",
    "all_upper_contour = np.append(y1_fit, y2_fit[::-1]) # upper line + reversed lower line \n",
    "all_lower_contour = np.append(y3_fit, y4_fit[::-1])\n",
    "\n",
    "# write it in a format so that the Path function can read it ( = as list of tuples)\n",
    "all_upper_contour= sorted(list(set(zip(np.append(x_up,x_up[::-1]), all_upper_contour))))\n",
    "all_lower_contour = sorted(list(set(zip(np.append(x_low,x_low[::-1]), all_lower_contour))))\n",
    "\n",
    "# find center coordinates \n",
    "# do a linear fit of the central value of y \n",
    "y_middle_up = (y1_fit + y2_fit)/2\n",
    "fit_param_center_up,_ =  curve_fit(func, x_up, y_middle_up)\n",
    "y_fit_center_up = fit_param_center_up[0]*x_up + fit_param_center_up[1]\n",
    "\n",
    "y_middle_low = (y3_fit + y4_fit)/2\n",
    "fit_param_center_low,_ =  curve_fit(func, x_low, y_middle_low)\n",
    "y_fit_center_low = fit_param_center_low[0]*x_low + fit_param_center_low[1]\n",
    "\n",
    "# upper pipette\n",
    "x_center_up = x_up[-1]\n",
    "y_center_up = y_fit_center_up[-1]\n",
    "\n",
    "# lower pipette\n",
    "x_center_low = x_low[-1]\n",
    "y_center_low = y_fit_center_low[-1]\n",
    "\n",
    "# calculate inclination angle of the pipettes \n",
    "# remember that in the image, the y axis points down (the zero is in the upper left corner of the image)\n",
    "\n",
    "#theta_up = np.arctan((y1_fit[-1] - y1_fit[0])/(x_up[-1] - x_up[0])) \n",
    "theta_up = (fit_param_y1[0] + fit_param_y2[0])/2\n",
    "theta_up = -theta_up # because I want the new y axis to point up when I do the rotation\n",
    "#theta_low = np.arctan((y3_fit[-1] - y3_fit[0])/(x_low[-1] - x_low[0]))\n",
    "theta_low = (fit_param_y3[0] + fit_param_y4[0])/2\n",
    "theta_low = - theta_low\n",
    "\n",
    "# Write pipette properties in a dictionary \n",
    "pipette_properties_dictionary = {\n",
    "                                'upper_contour' : all_upper_contour, \n",
    "                                'lower_contour' : all_lower_contour, \n",
    "                                'x_center_upper_pipette' : x_center_up,\n",
    "                                'y_center_upper_pipette': y_center_up, \n",
    "                                'theta_up' : theta_up, # inclination of the upper pipette\n",
    "                                'x_center_lower_pipette': x_center_low, \n",
    "                                'y_center_lower_pipette': y_center_low,\n",
    "                                'theta_low': theta_low # inclination of the lower pipette\n",
    "}\n",
    "\n",
    "# Save the pipette properties dictionary \n",
    "my_file = open(output_path+\"/pipette_properties_\"+video_name+\".txt\", \"wb\")\n",
    "pickle.dump(pipette_properties_dictionary, my_file)\n",
    "my_file.close()\n",
    "\n",
    "# Save image to check if pipette properties are all right\n",
    "\n",
    "# draw the x-line of the new axis centerd in the pipette center to check the rotation when right\n",
    "y_test_up = y_center_up - x_center_up*np.tan(-theta_up)\n",
    "test_up = [(x_center_up, y_center_up), (0, y_test_up)]\n",
    "y_test_low=  y_center_low - x_center_low*np.tan(-theta_low)\n",
    "test_low = [(x_center_low, y_center_low), (0, y_test_low)]\n",
    "\n",
    "\n",
    "## PLOT THE PIPETTE DETECTION PROFILE AND CENTER ON THE BCKG IMAGE\n",
    "\n",
    "#order x up\n",
    "list_x_up = [i[0] for i in pipette_properties_dictionary['upper_contour'][0::2] ]\n",
    "list_x_up_2 = [i[0] for i in pipette_properties_dictionary['upper_contour'][1::2] ]\n",
    "list_x_up.extend(list_x_up_2[::-1])\n",
    "\n",
    "#order y up\n",
    "list_y_up = [i[1] for i in pipette_properties_dictionary['upper_contour'][0::2] ]\n",
    "list_y_up_2 = [i[1] for i in pipette_properties_dictionary['upper_contour'][1::2] ]\n",
    "list_y_up.extend(list_y_up_2[::-1])\n",
    "\n",
    "# order the x low\n",
    "list_x_low = [i[0] for i in pipette_properties_dictionary['lower_contour'][0::2] ]\n",
    "list_x_low_2 = [i[0] for i in pipette_properties_dictionary['lower_contour'][1::2] ]\n",
    "list_x_low.extend(list_x_low_2[::-1])\n",
    "\n",
    "# order the y up\n",
    "list_y_low = [i[1] for i in pipette_properties_dictionary['lower_contour'][0::2] ]\n",
    "list_y_low_2 = [i[1] for i in pipette_properties_dictionary['lower_contour'][1::2] ]\n",
    "list_y_low.extend(list_y_low_2[::-1])\n",
    "\n",
    "%matplotlib\n",
    "fig = plt.figure(figsize = (13, 7))\n",
    "plt.imshow(Image.fromarray(bckg_arr_binary), cmap='gray')\n",
    "plt.plot(list_x_up, list_y_up, color = 'red', linewidth = 2)\n",
    "plt.plot(list_x_low, list_y_low, color = 'red', linewidth = 2)\n",
    "plt.scatter(int(x_center_up),y_center_up, marker = 'x', linewidths = 3,  s = 100, c = 'darkorange', zorder = 10)\n",
    "plt.scatter(int(x_center_low),y_center_low,marker = 'x', linewidths = 3, s = 100, c = 'darkorange',   zorder = 10)\n",
    "plt.savefig(output_path + \"/\" + video_name + \"_control_pipette_detection.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
